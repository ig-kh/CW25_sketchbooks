{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "s0sWne85Rc5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b69775a-7ea0-4c60-8b67-9a638aa43055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (6.3.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n"
          ]
        }
      ],
      "source": [
        "!pip install ftfy\n",
        "from ftfy import fix_text\n",
        "import gzip\n",
        "import json\n",
        "import polars as pl\n",
        "from collections.abc import Mapping, Sequence\n",
        "from collections import OrderedDict\n",
        "import tqdm\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ./data/raw_data"
      ],
      "metadata": {
        "id": "2gy5I8KiTR28"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L -o ./data/raw_data/items.json.gz https://mcauleylab.ucsd.edu/public_datasets/data/amazon_2023/raw/meta_categories/meta_Electronics.jsonl.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft40anHPSd-x",
        "outputId": "6b6217bd-ddd2-41c7-b532-a7bfde43ffe5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1252M  100 1252M    0     0  54.1M      0  0:00:23  0:00:23 --:--:-- 53.7M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./data/raw_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "886RQXBfTE11",
        "outputId": "a4947284-6b85-4132-fc1e-ebe52cc8f0b0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "items.json.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ATTR_STOP_WORDS = [\"bought_together\", \"image\", \"rating_number\", \"average_rating\", \"video\"]"
      ],
      "metadata": {
        "id": "ETbp9Gy5x3sn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_and_flatten_json(json_obj, parent_key='', separator='.'):\n",
        "    \"\"\"\n",
        "    Flatten a nested JSON object into a dictionary with dot-separated keys.\n",
        "\n",
        "    Args:\n",
        "        json_obj: The JSON object to flatten.\n",
        "        parent_key: The parent key for nested structures (used in recursion).\n",
        "        separator: The separator for nested keys (default: '.').\n",
        "\n",
        "    Returns:\n",
        "        A flattened dictionary.\n",
        "    \"\"\"\n",
        "    items = []\n",
        "    for key, value in json_obj.items():\n",
        "        new_key = f\"{parent_key}{separator}{key}\" if parent_key else key\n",
        "\n",
        "        list_in_meta = True\n",
        "\n",
        "        for stop_word in ATTR_STOP_WORDS:\n",
        "          if stop_word in new_key:\n",
        "            list_in_meta = False\n",
        "        if not list_in_meta:\n",
        "          continue\n",
        "\n",
        "        if new_key == 'main_category':\n",
        "          new_key = 'categories[0]'\n",
        "\n",
        "        if isinstance(value, Mapping):\n",
        "            items.extend(filter_and_flatten_json(value, new_key, separator).items())\n",
        "        elif isinstance(value, Sequence) and not isinstance(value, (str, bytes)):\n",
        "            for i, v in enumerate(value):\n",
        "                if isinstance(v, (Mapping, Sequence)) and not isinstance(v, (str, bytes)):\n",
        "                    items.extend(filter_and_flatten_json({f\"{new_key}[{i+1}]\": v}, '', separator).items())\n",
        "                else:\n",
        "                    items.append((f\"{new_key}[{i+1}]\", v))\n",
        "        else:\n",
        "            items.append((new_key, value))\n",
        "    return dict(items)\n",
        "\n",
        "def aggregate_sequential_attrs(attrs_dict):\n",
        "    cats_traversal = []\n",
        "    full_description = []\n",
        "    features = []\n",
        "    aggregated_dict = dict()\n",
        "    cats_pattern = r'^categories\\[\\d+\\]$'\n",
        "    desc_pattern = r'^description\\[\\d+\\]$'\n",
        "    feat_pattern = r'^features\\[\\d+\\]$'\n",
        "\n",
        "    for k, v in sorted(list(attrs_dict.items()), key=lambda x: x[0]):\n",
        "        if re.match(cats_pattern,k):\n",
        "          cats_traversal.append(v)\n",
        "        elif re.match(desc_pattern,k):\n",
        "          full_description.append(v)\n",
        "        elif re.match(feat_pattern,k):\n",
        "          features.append(v)\n",
        "        else:\n",
        "          aggregated_dict[k] = v\n",
        "\n",
        "    aggregated_dict[\"categories\"] = cats_traversal\n",
        "    aggregated_dict[\"description\"] = \". \".join(full_description)\n",
        "    aggregated_dict[\"features\"] = \"; \".join(features)\n",
        "\n",
        "    return aggregated_dict\n",
        "\n",
        "def extract_text_metadata_as_kv(metadata_file):\n",
        "    \"\"\"\n",
        "    Extract metadata from a JSONL.gz file and return a DataFrame with |asin|text| columns.\n",
        "\n",
        "    Args:\n",
        "        metadata_file (str): Path to the metadata JSONL.gz file (e.g., 'data/meta_All_Beauty.jsonl.gz').\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: DataFrame with columns 'asin' and 'text' (flattened JSON as string).\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    items_df = None\n",
        "\n",
        "    with gzip.open(metadata_file, 'rt', encoding='utf-8') as f:\n",
        "        for item_id, line in enumerate(tqdm.tqdm(f)):\n",
        "            item = json.loads(line)\n",
        "            asin = item.get('asin', item.get('parent_asin', ''))\n",
        "            if not asin:  # Skip if no asin or parent_asin\n",
        "                continue\n",
        "\n",
        "            # Remove asin and parent_asin from the JSON to avoid duplication in text\n",
        "            item_copy = item.copy()\n",
        "            item_copy.pop('asin', None)\n",
        "            item_copy.pop('parent_asin', None)\n",
        "\n",
        "            # Flatten the remaining JSON\n",
        "            flattened = filter_and_flatten_json(item_copy)\n",
        "            aggregated = aggregate_sequential_attrs(flattened)\n",
        "            # Convert flattened dictionary to JSON string\n",
        "            text = json.dumps(aggregated)\n",
        "\n",
        "            data.append({'item_id':item_id, 'asin': asin, 'text': fix_text(text.encode().decode('unicode-escape')), 'categories': aggregated[\"categories\"]})\n",
        "\n",
        "            if item_id % 128 == 127:\n",
        "              if items_df is None:\n",
        "                items_df = pl.from_dicts(data)\n",
        "              else:\n",
        "                items_df = pl.concat([items_df, pl.from_dicts(data)])\n",
        "              del data\n",
        "              data = []\n",
        "    return pl.concat([items_df, pl.from_dicts(data)])"
      ],
      "metadata": {
        "id": "tM3uBLLGT2gD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = extract_text_metadata_as_kv(\"./data/raw_data/items.json.gz\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7_7Z5rcWAyk",
        "outputId": "57a7cf0c-e120-4887-997a-0ede98540366"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1610012it [43:06, 622.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy8HFDm8Ym1H",
        "outputId": "2be87918-9257-4be8-aa04-466d7817de2d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1610012"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ./data/lvl1_data\n",
        "df.write_parquet(\"./data/lvl1_data/items.parquet\")"
      ],
      "metadata": {
        "id": "6-Ks3Y-VbJwU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item_id_mapping = dict(df.select(\"asin\", \"item_id\").iter_rows())"
      ],
      "metadata": {
        "id": "v2q1qkb9Cb7J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}